Gradient descent is an algorithm that numerically estimates where a function outputs its lowest values. That means it finds local minima, but not by setting $\nabla f = 0$ like we've seen before. Instead of finding minima by manipulating symbols, gradient descent approximates the solution with numbers. Furthermore, all it needs in order to run is a function's numerical output, no formula required.

Tries to get a value to approach the local minima or 0 by changing value to discover the minimums, like this

![[Drawing 2022-12-27 20.42.41.excalidraw]]

